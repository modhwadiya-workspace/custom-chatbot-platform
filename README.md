# Custom Chatbot Platform

A Docker-based chatbot platform supporting **FAQ**, **Workflow**, and **RAG (PDF-based)** conversations.  
Everything runs locally using Docker Compose.

---

## Core Idea

Each chatbot answers user messages in this order:

1. **FAQ** â€“ exact question match  
2. **Workflow** â€“ node-based conversation flow  
3. **RAG** â€“ semantic search over uploaded PDFs  

All chats are stored and replayable.

---

## Tech Stack

### Frontend
- Next.js (App Router)
- TypeScript
- React Flow (workflow UI)
- graphql-request (Hasura)

### Backend (RAG Service)
- FastAPI
- OCR: Tesseract + pytesseract
- PDF parsing: pdfplumber
- Text chunking
- Embeddings: Ollama (`nomic-embed-text`)
- Vector DB: Qdrant
- LLM (generation): Groq API

### Storage
- PostgreSQL (via Hasura)
- MinIO (PDF storage)
- Qdrant (vector storage)

### Infrastructure
- Docker Compose
- Everything runs locally (no hosting)

---

## Chat Resolution Flow

User Message
â†“
FAQ (exact match)
â†“
Workflow (userMessage match)
â†“
RAG (PDF search + LLM)


---

## Database Tables
ðŸ“˜ Chatbot Project â€“ PostgreSQL DB Schema (Quick Notes)
________________________________________

ðŸŸ¢ 1. chatbots â€” Core Master Table

Purpose:  
Stores basic chatbot configuration and identity.

Columns:  
â€¢ id (UUID, PK) â†’ Unique chatbot identifier  
â€¢ name (Text) â†’ Chatbot name  
â€¢ start_message (Text) â†’ First message shown to user  
â€¢ created_at (Timestamp) â†’ Creation time (default: now())

Notes:  
â€¢ Parent table for most relationships  
â€¢ One record = one chatbot  

________________________________________

ðŸŸ¢ 2. faqs â€” Static Questionâ€“Answer Data

Purpose:  
Stores predefined FAQs related to a chatbot.

Columns:  
â€¢ id (UUID, PK)  
â€¢ chatbot_id (UUID, FK â†’ chatbots.id)  
â€¢ question (Text)  
â€¢ answer (Text)

Relationships:  
â€¢ Many FAQs â†’ One chatbot  

Notes:  
â€¢ Used for instant responses without workflow logic  

________________________________________

ðŸŸ¢ 3. workflows â€” Conversation Flow Logic

Purpose:  
Stores chatbot conversation logic as JSON.

Columns:  
â€¢ id (UUID, PK)  
â€¢ chatbot_id (UUID, FK â†’ chatbots.id)  
â€¢ flow_json (JSONB) â†’ Nodes, messages, options, positions  

Notes:  
â€¢ One workflow per chatbot  
â€¢ JSONB allows flexible flow design  
â€¢ Used for guided conversations  

________________________________________

ðŸŸ¢ 4. chat_sessions â€” User Interaction Session

Purpose:  
Tracks each chatbot interaction session.

Columns:  
â€¢ id (UUID, PK)  
â€¢ chatbot_id (UUID, FK â†’ chatbots.id)  
â€¢ created_at (Timestamp)

Notes:  
â€¢ Each page reload = new session  
â€¢ Groups messages logically  

________________________________________

ðŸŸ¢ 5. chat_messages â€” Chat History

Purpose:  
Stores all messages exchanged in a session.

Columns:  
â€¢ id (UUID, PK)  
â€¢ session_id (UUID, FK â†’ chat_sessions.id)  
â€¢ sender (Text) â†’ user / bot  
â€¢ message (Text)  
â€¢ created_at (Timestamp)

Notes:  
â€¢ Core table for chat history  
â€¢ Used for analytics, logs, and debugging  

________________________________________

ðŸ”— Relationship Summary (One Line)

â€¢ chatbot â†’ FAQs, workflow, sessions  
â€¢ session â†’ messages  

________________________________________

## Workflow JSON Structure

```json
/**
 * Example workflow JSON stored in database (flow_json):
 
  {
    "nodes": [
      {
        "id": "node-1",
        "userMessage": "Check order status",
        "botReply": "Please enter your order number.",
        "options": [
          { "nextNodeId": "node-2" }
        ],
        "position": { "x": 100, "y": 120 }
      },
      {
        "id": "node-2",
        "userMessage": "Talk to support",
        "botReply": "Connecting you to support.",
        "options": [],
        "position": { "x": 420, "y": 260 }
      }
    ]
  }
 /
```
---

## RAG Pipeline

```text
PDF Upload
 â†’ OCR (mandatory)
 â†’ Text Chunking
 â†’ Embeddings (local)
 â†’ Store in Qdrant
 â†’ User Query
 â†’ Similar Chunk Search
 â†’ Prompt Creation
 â†’ Groq LLM Response
Notes:

OCR is mandatory for all PDFs.

Embeddings and vector search are fully local.

Only the final response generation uses Groq (cloud).

No document data is sent to the cloud.
```

## Services & URLs
Service	URL
```
Frontend	http://localhost:3000
Hasura Console	http://localhost:8080
Hasura GraphQL API	http://localhost:8080/v1/graphql
RAG Backend API	http://localhost:8000
MinIO UI	http://localhost:12001
Qdrant Dashboard	http://localhost:6333/dashboard
Ollama	http://localhost:11434

RAG API
Endpoint
POST /chat/rag?chatbot_id=UUID&user_message=TEXT
Request Body (Optional â€“ Chat History)
[
  { "role": "user", "content": "previous message" },
  { "role": "bot", "content": "previous reply" }
]

```
## Current Features
Admin chatbot CRUD

FAQ management

Workflow editor (drag & drop)

User chat UI

Session & message storage

PDF upload via backend API

OCR and text chunking

Vector search using Qdrant

RAG-based responses using Groq LLM

## Architecture Overview
Frontend: Admin panel and user chat UI

Backend (RAG API): OCR, chunking, embeddings, retrieval, prompt creation

Vector Database: Qdrant

Object Storage: MinIO (PDFs)

Metadata & Auth: Hasura (PostgreSQL)

LLM: Groq (generation only)

## Local-First Design
PDFs, extracted text, embeddings, and vectors stay local.

Cloud usage is limited strictly to LLM inference.

Designed for privacy, performance, and cost efficiency.
