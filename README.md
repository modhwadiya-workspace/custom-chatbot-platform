“We avoided PyTorch to reduce memory and build time.
We used Ollama’s embedding models, which are lighter and production-safe for local RAG.”

PDF
↓
OCR  ✅
↓
Chunking  ✅
↓
Ollama embeddings 
↓
Qdrant
↓
Ollama LLM (answer)
